# 项目亮点
- 使用分布式Session，可以实现让多台服务器同时可以响应
- 使用redis做缓存提高访问速度和并发量，减少数据库压力，利用内存标记减少redis的访问
- 使用页面静态化，加快用户访问速度，提高QPS，缓存页面至浏览器，前后端分离降低服务器压力
- 使用消息队列完成异步下单，提升用户体验，削峰和降流
- 安全性优化：双重md5密码校验，秒杀接口地址的隐藏，接口限流防刷，数学公式验证码

# 秒杀流程
1. 登录进入商品列表页面，静态资源缓存
2. 点击进入商品详情页面，静态资源缓存，Ajax获取验证码等动态信息
3. 点击秒杀, 将验证码结果和商品ID传给后端，如果结果正确。动态生成随机串UUID,结合用户ID和商品ID存入redis，并将path传给前端。前端获取path后，再根据path地址调用秒杀服务
4. 服务端获取请求的path参数，去查缓存是否在
5. 如果存在，并且Redis还有库存，预减redis库存，看是否已经生成订单，没有的话就将请求入消息队列
6. 从消息队列中取消息：获取商品ID和用户ID，判断数据库库存，然后下单
7. 下单：减库存，生成订单
8. 前端轮询订单生成结果。50ms继续轮询或者秒杀是否成功和失败

# 一. 环境的搭建

# 二. 登录功能的实现
## 1. 主要内容

1. **数据库设计**
2. **明文密码两次MD5处理**
3. **JSR303参数检验**
4. **分布式Session**

## 2.**数据库设计**

1. 不做注册，直接登录，在MySQL中直接创建表
2. 用户表包括id、nickname、password、salt、头像、注册时间、上次登录时间、登录次数等字段

##3. **对登录密码进行两次**MD5

写一个MD5Util，通过调用DigestUtils的md5Hex方法实现的

​	加密的目的：第一次是因为http是明文传输的，第二次为了防止数据库被盗

```
1. 两次MD5加密
用户端：PASS = MD5（明文+固定salt）
服务端：PASS = MD5（用户输入+随机salt）
2. 为什么要进行两次加密？
第一次加密是因为http采用明文传输，若传输的数据包被截取，那么密码就会被别人知道
第一次是用户端对密码进行加密，防止传输过程中的密码泄露
第二次加密是防止数据库被盗，因为MD5有些加密后是可以通过彩虹表进行反向查询得到原始密码，所以第二次MD5是为了保险起见（相当于加了双保险）
第二次是服务器对一次MD5加密后的输出进行再次加密，加密后存入数据库
```

## 4. **JSR303参数检验**

1. 可以用来校验参数是否满足格式要求。通过对输入的参数LoginVo加注解@validated，然后在传入的参数mobile和password上加上注解判断，如@NotNull判断是否为空，也可以自定义

## 5. **分布式Session**

（将token存放到cookie，将用户信息放到缓存，根据token取redis中取用户信息）

秒杀实际中一定不可能只有一台服务器，肯定是有多台服务器

如果用户的第一个请求落到了第一个服务器，而第二个请求落到了第二个服务器上，那么session信息就全部丢失了

> 容器可以提供原生的session同步，一台服务器的session同步到另一台服务器上，集群中无论哪一台服务器都会保存有用户的session，这种方式实际中应用的比较少，首先是性能问题，其次是实现起来比较复杂
>
> 比如有十台服务器，所有的session都要同步，需要消耗许多资源

服务端在用户登录成功给用户返回一个token(代表)相当于sessionid(ssid)来表示用户，写入到cookie当中，cookie写入到response中，同时第一次登陆时用户信息也会存放到redis缓存中，传递给客户端，客户端在随后的访问中都在cookie中上传这个token，然后服务端拿到token之后就据此到redis中取到用户对应的session信息。

cookie的过期时间和token一样，有效期是最后依次登录时间加上过期时间

**首先生成一个uuid的帮助类**

```java
public class UUIDUtil {
	public static String uuid() {
		return UUID.randomUUID().toString().replace("-", "");
	}
}
```

需要知道token：uuid对应的哪一个用户，需要把用户信息写到redis当中

核心就是把私人信息存放到一个第三方的缓存当中，十分高效

**MiaoShaUserKey.java定义了秒杀userkey的前缀，根据token就可以知道用户信息了 token即是key，用户信息即是value**

登录成功即跳转到商品列表页good_list，新建一个goodController跳转到此页面

测试要点：用户信息能否写到redis当中，cookie能否写到response当中

**实现有效期延长，即最终的有效期是用户最后登录时间+过期时间**

注入user的方法：新建一个webconfig 使用springMVC框架

框架回调addArgumentResolvers方法往controller里的方法赋值

编写UserArgumentResolver解析user对象，这样子即使以后获取session的方式改变了，只需要在此调整即可，不用在业务中调整，里面实现了和客户端兼容，不想从cookie传参，想从参数传参，不需要修改后端代码

**分布式session的一些优化——双token刷新机制**

不需要每次访问都去刷新token课程中在每次调用 getby Token（）去获取用户信息的时候，都去做了一件事：那就是去延长当前 token的有效期

![image-20210404174306704](C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210404174306704.png)

这样在访问频繁的系统中对 redis的压力太大了，更常用的一种做法是：登录成功以后返回两个 token:一个是 accesstoken,另一个是 refreshtoken 其中， accessToken就是课程中所讲的那个 token,但是当用户带着 accessToken来访问的时候，并不去刷新 accessToken, 而是**提供一个 refreshTokenl的方法，让客户端定时来调用**，调用的时侯需要传递refreshToken。这样，就可以最大限度的減少 accessToken的刷新。

**todo双token刷新机制**

 token过期了**活跃**用户需要在登录页面重新登录 问题，我们需要**token刷新**

第一次用账号密码登录服务器会返回两个 token : access_token 和 refresh_token，时效长短不一样。短的access_token 时效过了之后，发送时效长的 refresh_token 重新获取一个短时效token，如果都过期，就需要重新登录了。

refresh_token 就是用来刷新access_token 。活跃用户的 access_token 过期了，用refresh_token 获取 新的access_token 。

# 三. 实现秒杀功能

## 1. 主要内容

1. 数据库设计
2. 商品列表页
3. 商品详情页
4. 订单详情页

##2. 数据库设计
数据库：商品表——订单表——秒杀商品表——秒杀订单表

秒杀商品表创建的目的：如果每一次活动如秒杀大促包邮都在商品表中添加秒杀的字段，那么商品表将变得越来越臃肿，难以维护

## 3. 商品列表页
为了展示秒杀商品的详情需要goods和miaosha_goods中的信息，所以封装一个GoodsVo，包括价格、库存、秒杀起始时间

> vo value object表现层对象

## 4. 商品详情页

**商品详情页的编写**

判断用户信息是否完整

**秒杀倒计时**

秒杀是否开始，实现一个倒计时的功能

未开始0、开始1、结束2

**只有在秒杀开始的时候秒杀按钮才能够点，否则需要将秒杀按钮置灰，这是前端的任务**

倒计时是在客户端完成的，要是都请求服务端的话量非常大，没法和服务端的时间保持一致，偶尔不精确，可以想办法保持同步

页面从接收到服务器响应的时间戳开始计时，计时的时长应减掉AJAX从发送到接收整个过程的耗时，计时过程则使用本地时间来实现（本地时间+时间偏差）。

**实现秒杀功能**

总共有四步，首先判断库存，然后判断是否重复秒杀，然后减库存，下订单(订单表，秒杀订单表)

就是做了一个表单的提交，提交了商品id，用**MiaoController类**实现秒杀功能do_miaosha

**首先判断用户是否登录**，如果没有登录首先登录

**判断库存是否为空**，如果库存为空，直接返回秒杀失败，**秒杀失败的页面**

**判断是否秒杀到了**，防止一个人秒杀了多次商品，返回重复秒杀

这是在orderservice中完成查询的，

创建**OrderService**，注入OrderDao

OrderService中下单操作也需要放在一个事务中进行

创建**OrderDao**

**减库存，下订单，写入秒杀订单**（原子操作），**订单详情页**

只有减库存成功才会生成订单

某个用户秒杀了某个商品，返回生成的订单，秒杀成功之后直接进入订单详情页有订单信息orderInfo，商品信息goods

这几步需要放在一个事务中进行，一步成功，其他两步必须要成功，一步失败，其他两步都不许失败

**创建MiaoshaService**

同一个service尽量值注入自己的dao，如果要注入其它的dao则要注其他的service

## 5. 订单详情页

显示订单详情

商品名称+商品图片+订单价格+下单时间+订单状态+收货人+收获地址

订单状态0新建未支付，1已支付，2已发货，3已收货，4已退款，5已完成

> 如果是一些其他的例如手机充值，状态需要跟着改

# 四. JMeter压测

## 1. 主要内容

1. JMeter入门
2. 自定义变量模拟多个用户
3. JMeter命令行使用
4. Redis压测工具redis-benchmark
5. Spring Boot打war包

## 2. JMeter入门

准确的说法：并发在多少的时候，网站的qps是多少

> TPS (transaction per second)代表每秒执行的事务数量
>
> QPS（Queries-per-second） 每秒查询率
>
> 事务：客户端发起请求到收到服务端最终响应的整个过程，这是一个TPS
>
> 而在这个TPS中，为了处理第一次请求可能会引发后续多次对服务端的访问才能完成这次工作，每次访问都算一个QPS。
>
> 所以，一个TPS可能包含多个QPS

聚合报告，并发在1000的时候，qps只有84，瓶颈在数据库

并发在10000时，qbs192.6，服务器负载超过3，已经有很多进程在等待了

## 3. 自定义变量模拟多个用户

编写usercontroller获取用户的个人信息

1000个请求，qps差不多431，getByToken，由于读的是缓存

配置元件csv data set config，导入文件，变量的名字，定义了几个就写几个，分隔符等等

userid1.usertoken1

userid2.usertoken2

userid3.usertoken3

可以设置recycle，然后再httprequest中写入${userToken}，也就是配置文件的变量

这一次1000个请求，qps差不多686.9，由于之前有热身，redis中已经有缓存了

## 4. JMeter命令行使用

JMeter在Linux下是命令行进行操

- 在Windows上录好jmx
- 命令行：sh jmeter.sh -n -t XXX.jmx -l result.jtl
- 把result.jtl导入到jmeter

## 5. Redis压测工具redis-benchmark

**1.redis-benchmark**

redis-benchmark -h 127.0.0.1 -p 6379 -c 100 -n 100000 
100个并发连接，100000个请求，get请求一秒可以完成10w，以3bytes进行测试

<img src="C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210405140722943.png" alt="image-20210405140722943" style="zoom:80%;" />



redis-benchmark -h 127.0.0.1 -p 6379 -q -d 100 
存取大小为100字节的数据包，10w qps

<img src="C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210405141450617.png" alt="image-20210405141450617" style="zoom:80%;" />

redis-benchmark -t set,lpush -n 100000 -q
只测试某些操作的性能set，lpush 11wqps

<img src="C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210405141534962.png" alt="image-20210405141534962" style="zoom:80%;" />

redis-benchmark -n 100000 -q script load "redis.call(‘set’,‘foo’,‘bar’)"
只测试某些数值存取的性能 12w qps

<img src="C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210405141822071.png" alt="image-20210405141822071" style="zoom:80%;" />

## 6. Spring Boot打war包

（1）修改pom

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-tomcat</artifactId>
	<scope>provided</scope>
</dependency>
```

  编译时通过就可以了，运行时不需要，运行时是由tomcat的

maven-war-plugin放在一个build中，修改artifactid打出来是一个war包

```xml
<finalName>${project.artifactId}</finalName>    
<plugin>
	<groupId>org.apache.maven.plugins</groupId>
	<artifactId>maven-war-plugin</artifactId>
	<configuration>
		<failOnMissingWebXml>false</failOnMissingWebXml>
	</configuration>
</plugin>
```

（2）修改启动类

```java
public class MainApplication extends SpringBootServletInitializer{
	    @Override
	    protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {
	        return builder.sources(MainApplication.class);
	    }
}
```

这样即可以以jar包形式跑又可以以war包形式跑

## 7. 实际压测

在windows上录好jmx

命令行：sh jmeter.sh -n -t XXX.jmx -l result.jtl 

-n不使用图形界面 -t使用脚本 -l保存输出结果到result.jtl 

把result.jtl导入到jmeter

这是打jar包的插件

```xml
<plugin>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-maven-plugin</artifactId>
</plugin>
```

nohup java -jar -server -Xmx2048m -Xms2048m  miaosha.jar &

nohup: 忽视输出并且把输出追加到”nohup.jar“

录制goods_list.jmx脚本，上传到服务器，5000 0 10 并发数 延迟时间 循环次数

jmeter安装到linux服务器

jmeter.sh -n -t goods_list.jmx -l result.jtl执行脚本进行压测，4核的服务器负载有13，说明进程发生严重阻塞，java，jmeter（java写的），mysql几个进程

下载result.jtl结果文件 sz.result.jtl，用window的jmeter客户端加载文件，查看聚合报告，发现qps大概有600，这是一次热身

删除刚才的结果文件rm -rf result.jtl

再次执行nohup java -jar -server -Xmx2048m -Xms2048m  miaosha.jar &

系统负载到9

下载result.jtl结果文件 sz.result.jtl，用window的jmeter客户端加载文件，查看聚合报告，发现qps大概有1267，将这个作为基准，后续对其进行优化

后面在对秒杀进行压测，需要更改一下

（1）列表页压测-记录QPS 

```
QPS:1267 load:15 mysql -- 第二次
5000 * 10
```

（2）秒杀压测，记录QPS，模拟多用户卖超，改sql，同一个用户卖超加主键

-- 业务有判断库存，是否重复秒杀，如果不是那么才减库存，下订单，写入秒杀订单，比较复杂

生成多用户然后导入csv data set config，在http请求中添加两个参数

一个是商品id value；另外一个是token，value是${token}

生成miaosha.jmx上传到服务器 5000 0 10 并发数 延迟时间 循环次数，需要把jmx中的存放用户信息的路径改为服务器的路径/tmp

```
QPS:1306 load:15 mysql
5000 * 10
```

**发现商品超卖了，超卖原因：**商品有1个库存，两个线程过来发现都有库存，就都去执行秒杀，恰巧之前又都没有秒杀到，所以都执行减库存，下订单的操作，导致都减1，商品超卖

# 五. 页面优化技术

##1. 主要内容

1. 页面缓存+URL缓存+对象缓存
2. 页面静态化，前后端分离
3. 静态资源优化
4. CDN优化

##2. 页面缓存+URL缓存+对象缓存

1. 秒杀的瓶颈在于数据库，所以要加上各种粒度的缓存，最大的是页面缓存、最小的是对象缓存

2. 页面缓存步骤（这里指的是商品列表）：

   1. 从redisService中取缓存
   2. 若缓存中没有则手动渲染，利用thymeleaf模板
   3. 然后将页面加入缓存，并返回渲染页面
   4. 不宜时间太长，设置为60s即可

3. URL缓存（指的是商品详情页）

   1. 与页面缓存步骤基本一致，但是需要取缓存和加缓存时要加入参数，GoodsId

4. 对象缓存（指的是User对象）

   热点数据对象缓存：用户token，getById改造,对象设置为永不过期，只要对象没有发生变化，那么就一直可用

   1. 前面的页面缓存和URL缓存适合变化不大的，缓存时间比较短
   2. 对象缓存是长期缓存，所以需要有个更新的步骤
   3. 第一步是取缓存
   4. 若缓存中没有则去数据库中查找，并加入缓存；如数据库中没有就报错
   5. 更新用户的密码，需要提供数据库密码修改语句update password

5. **加缓存之后的QPS大概3000**

6. 对象需要先更新数据库，后删除缓存；顺序不能反，会导致数据不一致：若线程1先删除缓存，然后线程2读操作，发现缓存中没有，把数据库中的旧数据加入缓存，然后线程1更新数据库，就会导致缓存与数据库数据不一致（旁路缓存更新模式）

## 3. 页面静态化，前后端分离

1. 页面静态化无非就是使用纯html页面+Ajax请求json数据后再填充页面
2. 若A页面跳转到B页面之前需要条件判断可以先在A页面中利用ajax请求判断后再跳转
3. 如果不需要条件判断可以直接跳转到B的静态页面，让B自己用ajax请求数据

## 4. 防超卖

1. 发生在减库存的时候

2. 解决方法是在Update语句中加一个判断

   - 修改减少库存的SQL，要判断库存是大于0才能减，数据库会对这条记录加一个行锁，不会出现两个数据更新同一条数据的情况，通过数据库保证不会超卖，但是不够

   - 例如库存有10，但某一个用户抓取接口，同时发出了两个请求req1，req2，首先判断库存是否大于0，由于这两个请求之前都没有秒杀过，所以会进行减库存，下订单，写入秒杀订单的操作，**导致一个用户重复秒杀**，在秒杀订单表加一个**唯一索引**，商品id+用户id，秒杀订单表一个用户只能写入一条记录，如果重复秒杀，会报错，事务会回滚，同时在实际情况中，用户在提交订单前会进行验证，也保证了不会重复秒杀

**压测秒杀接口，同一个token  同一个goodsId,20个并发 演示卖超**

nohup java -jar miaosha.jar执行秒杀

jmeter.sh -n -t miaosha.jmx -l result.jtl

top看服务器负载

```
第一次qps900多，load 11左右，发现不会买超
```

**redis解决并发问题加锁，乐观锁和悲观锁，redis集群的时候加一个分布式锁**

## 5. CDN优化

CDN是内容分发网络，相当于缓存，只是部署在全国各地，当用户发起请求时，会找最近的CDN获取资源

## 6. 总结

​		并发大的瓶颈在于数据库，所以解决办法是加各种缓存：从浏览器开始，做页面的静态化，将静态页面缓存在浏览器中；请求到达网站之前可以部署一些CDN，让请求首先访问CDN；然后是页面缓存、URL缓存、对象缓存；

​		**加缓存的缺点：数据可能不一致，只能做一个平衡**

# 六. 接口优化
##1. 内容

1. Redis预减库存减少数据库访问
2. 内存标记减少Redis访问
3. RabbitMQ队列缓冲，异步下单，增强用户体验
4. RabbitMQ安装与Spring Boot集成
5. 访问Nginx水平扩展
6. 压测

##2. 思路：减少数据库访问

1. 系统初始化，把商品库存数量加载到Redis中
2. 收到请求，Redis预减库存，库存不足，直接返回，否则进入3
3. 请求入队，立即返回排队中
4. 请求出队，生成订单，减少库存
5. 客户端轮询，是否秒杀成功

##3. 秒杀接口优化

1. 之前的没有库存预热的步骤是：查库存-查订单-修改库存-生成订单
2. 系统初始化时把库存加载到数据库：MiaoshaController 继承InitializingBean实现afterPropertiesSet方法即可
3. 在上一步库存预热之后，执行步骤为：查Redis库存-判断是否存在订单-进入队列-在出队时才对数据库进行操作
4. 这一步还可以有一个优化，就是内存标记，使用一个Map，将商品ID设置为false，当买空时，设为true；然后每次不是直接访问Redis进行库存查询，而是对商品ID进行条件判断
5. 内存标记的优点是减少对Redis的访问（当商品已经卖完之后）

在miaoshacontroller中建立一个localovermap，存放商品id和是否结束的标记，这个是放在controller里面的

![image-20210406101543451](C:\Users\94307\OneDrive - zju.edu.cn\learnbm\JAVA\学习笔记\image-20210406101543451.png)

判断内存标记是否为true，如果为true那么就秒杀结束，直接返回一个error

而在预减库存之后，判断库存是否小于0，如果小于0，那么就设置秒杀结束标记，同时此人秒杀失败；不能在等于0的时候设置秒杀结束标记，倘若一个人秒杀了最后一个商品，此时预减库存之后，库存为0，这时候，由于设置秒杀标记和返回失败在一起，所以最后一个秒杀失败。也就是说，只有预减完库存小于0，即执行秒杀前库存为0，秒杀失败，设置秒杀标志。

在之后的请求过来，首先查询内存标记，如果标记为true直接返回秒杀失败，不会访问redis，也不会发给数据库。

## 4. 再压测

（改造秒杀业务主要体现在redis预读库存，然后用消息中间件去扣库存）
压测秒杀接口 再压测获取秒杀结果接口

> 可以搞一个reset接口，每次在压测前还原库存

用户token文件5000个用户token.txt，秒杀一个商品，然后测试脚本文件miaosha.jmx上传到服务器，然后用jmeter进行测试，

top看负载，java-秒杀，java-jmeter，redis-缓存读写

```
5000线程*10个循环，总共50000个请求
QPS 1300	load 25	-- 第一次热身
QPS 2114	load 5 	-- 正式跑，前端做的事情很少，不用读动态数据
```

4核cpu快到性能极限，mysql redis rabbitMQ jmeter web程序在同一台服务器

真实情况mysql一台服务器，redis在一台服务器，rabbitMQ在一台服务器，web程序在一台服务器会准确一点

## 5. nginx水平扩展

利用nginx代理，将请求分发给多台服务器

## 6.消息队列的使用

1.SpringBoot集成RabbitMQ
（1）添加依赖

amqp是消息队列的标准协议

```xml
<dependency>  
<groupId>org.springframework.boot</groupId>  
<artifactId>spring-boot-starter-amqp</artifactId>  
</dependency>  
```

（2）添加配置：

```properties
spring.rabbitmq.host=10.110.3.62
spring.rabbitmq.port=5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
```

消费者数量

```properties
spring.rabbitmq.listener.simple.concurrency= 10
spring.rabbitmq.listener.simple.max-concurrency= 10
```

消费者每次从队列获取的消息数量

```properties
spring.rabbitmq.listener.simple.prefetch= 1
```

消费者自动启动

```properties
spring.rabbitmq.listener.simple.auto-startup=true
```

消费失败，自动重新入队

```properties
spring.rabbitmq.listener.simple.default-requeue-rejected= true
```

启用发送重试

```properties
spring.rabbitmq.template.retry.enabled=true 
spring.rabbitmq.template.retry.initial-interval=1000 
spring.rabbitmq.template.retry.max-attempts=3
spring.rabbitmq.template.retry.max-interval=10000
spring.rabbitmq.template.retry.multiplier=1.0
```

(3)MQSender：创建发送者

(4)MQReceiver：创建消费者

2.为了让guest用户能远程连接，修改rabbitmq的配置/usr/local/rabbitmq/etc/rabbitmq/rabbitmq.config
添加：[{rabbit, [{loopback_users, []}]}].
重新启动
http://www.rabbitmq.com/access-control.html

启用管理控制台
./sbin/rabbitmq-plugins enable rabbitmq_management
重启rabbitmq。

3.添加demo测试

4.admin
rabbitmq-plugins enable rabbitmq_management 

5.4种exchange交换机
FanoutExchange: 将消息分发到所有的绑定队列，无routingkey的概念  
HeadersExchange ：通过添加属性key-value匹配  
**DirectExchange:  按照routingkey分发到指定队列**  
TopicExchange:  多关键字匹配  

**消息队列的作用**

1. **通过异步处理提高系统性能（减少响应所需时间）。**
2. **削峰/限流**
3. **降低系统耦合性。**

# 七. 安全优化

## 1. 主要内容

1. 秒杀接口地址隐藏
2. 数学公式验证码
3. 接口限流防刷

**秒杀开始之前，先去请求接口获取秒杀地址**

**错峰请求秒杀接口**
**请求完了详情接口之后，接着去请求获取验证码的接口**
**在点击秒杀获取路径的时候，去验证验证码**

##2. 秒杀接口地址隐藏

> 请求秒杀接口之前先去请求秒杀路径，请求秒杀路径时要进行数学验证码
>
> 秒杀地址是要从服务端获取动态拼接，进行秒杀之前要验证秒杀地址是否准确

改造getmiaoshapath的接口，动态生成秒杀地址，在redis中存放秒杀路径的key和value，key是前缀（类名+mp）+ 用户id + 商品id + uuid(每次随机生成)

秒杀接口加上PathVariable参数，添加秒杀地址的参数，同时需要验证秒杀地址

客户端轮询的时间可以适当设置长一点，例如200ms防止服务器压力过大。

## 3.数学公式验证码,

生成数学计算题，SriptEngine

**防止机器人刷单，防止用户高频点击，将用户的请求分散到了做题时间之内削减并发量**

写一个生成图片验证码的接口，bufferedrimage

用随机数和一个操作数组来生成计算公式

计算用SriptEngine实现，调用js的引擎，引用其中的eval方法

用户输入的验证码通过requestParam注入到获取秒杀地址的接口中八. 总结

## **4.接口防刷**

**针对需要用户登录的接口做限流**

前端是不可以限流的，http是明文传输的

比如：限制10秒以内对某个接口最多请求10次，还是用redis
以秒杀接口为例，可以把用户和限流用拦截器来做

>  放到缓存中做，在缓存中设置一个表示操作次数的数据，设计一个有效期，例如60s，如果在60s内重复点击，那么这个数就加1，超过10次就返回操作失败，到达下一个60s就再从0开始计时。

这是改造前的，放在获取秒杀地址方法里，需要在redis中存放一个key

```java
// 查询访问的次数
String uri = request.getRequestURI();
String key = uri + "_" + user.getId();
Integer count = redisService.get(AccessKey.access, key, Integer.class);
if (count == null){
	redisService.set(AccessKey.access, key, 1);
} else if(count < 5){
	redisService.incr(AccessKey.access, key);
} else {
    return Result.error(CodeMsg.ACCESS_LIMIT_REACHED);
}
```

如果有多个方法都需要限流，可以使用拦截器，在每个方法前使用如下注解即可

@AccessLimit(second = 5, macCount = 5, needLogin = true)

在拦截器中完善代码

ThreadLocal关键字：多线程的时候保证线程安全的访问方式，threadlocal是和当前线程绑定的，往threadlocal放东西释放到当前线程来，不会存在线程冲突问题。

## **5.回仓：30分钟不支付订单自动取消**
30分钟以后，扫描下秒杀订单，看有哪些还没支付，把订单状态置为已经取消，可秒杀数量+1，redis的秒杀结束的标志位还原

## **补充：为什么要做秒杀地址的隐藏？**

课程中仅仅是通过动态生成秒杀url+数学验证码+防刷限流的方式

而在实际开发中，有一种更为有效的实现方式，在活动开始的时候，通过后台，重新设置一个url，客户端拿到后直接跳转。这样可以防止恶意用户提前抓取网页，对网页进行分析，然后写出刷接口的机器人。活动开始之前，恶意用户就算分析了网页写了刷接口的程序也没有用，因为那个页面不是真正的秒杀页面

## **有哪些常用的接口限流防刷的实现方式？**

常见的限流算法：
 最常用限流算法的就是使用**令牌桶**或者**漏斗桶算法**
 常见的实现方式
 (1)在网关上做限流。比如在 nginx上写ua脚本来实现
 (2)在应用上做单机限流。使用诸如基于 Guava的 Rate Limiter令牌桶的方式。
 (3)在应用上做分布式限流。比如 radisson提供了个基于 redis的 Rate Limiter:
https://github.com/redisson/redisson/wiki/6.-distributed-objects#612-ratelimiter
 (4)如果是 Spring Cloud项目，可用的就更多了，比如 Spring Cloud Gateway, Sentinel等等。

# 秒杀常见问题

## **1.redis事务处理**

我们可以使用redis中的监听（watch）方法，去监听库存数量，一旦库存数量在其他客户端发生改变，后续操作则会失败。

## **2. redis分布式锁**

分布式锁确保只有一个线程会操作库存

- 加锁（占个位置，后续的进不来）：setnx命令: 只在键key不存在的情况下，将键key的值设置为value 。若键key已经存在， 则不做任何动作。
- 解锁（用完了，就把位置让出来）：del（key）
- 锁超时（万一中间出现点意外，没有解锁，过几秒会自动释放）expire（key，30）

**单库高并发脏数据处理**

悲观锁

即使Redis是单线程的，但是在多线程的情况下，可能会出现脏读这样的问题。比如，线程A从Redis读到key X的值=1，线程B也读到1，但是线程A读到之后进行计算将其改为2，线程B的值还是1，还在用拿到的1进行业务计算，这样就会出问题。通过setnx设置一把锁，每个线程过来，只有获取了锁才能继续操作，否则就重试，获得锁的线程执行自己的计算操作，执行完之后，删掉锁，这样其他的线程再进来执行的时候，数据就是最新的。不会出现脏读的问题。

乐观锁 

redis中可以使用watch命令会监视给定的key，当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败。也可以调用watch多次监视多个key。这样就可以对指定的key加乐观锁了。注意watch的key是对整个连接有效的，事务也一样。如果连接断开，监视和事务都会被自动清除。当然了exec，discard，unwatch命令都会清除连接中的所有监视。

Redis事务
Redis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。Redis事务的实现需要用到 MULTI 和 EXEC 两个命令，事务开始的时候先向Redis服务器发送 MULTI 命令，然后依次发送需要在本次事务中处理的命令，最后再发送 EXEC 命令表示事务命令结束。Redis的事务是下面4个命令来实现 

1.multi，开启Redis的事务，置客户端为事务态。
2.exec，提交事务，执行从multi到此命令前的命令队列，置客户端为非事务态。
3.discard，取消事务，置客户端为非事务态。
4.watch,监视键值对，作用时如果事务提交exec时发现监视的监视对发生变化，事务将被取消。

## **3.redis队列（rpoplpush的安全队列）**

把每一件商品都lpush到redis队列中，利用lpop从队列中去取

## 4.  如何保证不卖超

有两种情况可能会导致卖超：（1）一个用户同时发出了多个请求，如果库存足够，没加限制，用户就可以下多个订单。（2）减库存的sql上没有加库存数量的判断，并发的时候也会导致把库存减成负数。

我们的解决办法：

对于（1）：前端加验证码，防止用户同时发出多个请求，在后端的miaosha_order表中，对user_id和goods_id加唯一索引，确保一个用户对一个商品绝对不会生成两个订单。

对于（2）：我们的减库存的sql上应该加上库存数量的判断：                          

数据库更新记录的时候会加锁，实际上是串行的执行update的，因此绝对不会卖超！

## 5.  Redis中的库存如何与DB中的库存保持一致？

Redis中的数量不是库存，它的作用仅仅时候只是为了阻挡多余的请求透传到db，起到一个保护DB的作用。因为秒杀商品的数量是有限的，比如只有10个，让1万个请求去访问DB是没有意义的，因为最多只有10个请求会下单成功，剩余的9990个请求都是无效的，是可以不用去访问db而直接失败的。

**可以通过消息队列，去异步扣减库存**

因此，这是一个伪问题，我们是不需要保持一致的。

## 6.  Redis预减成功，DB扣减库存失败怎么办？即少卖

两大类情况可导致redis预减成功而DB扣减失败：

（1）   如果一个用户发出了多个请求（不管何种手段），而这些所有的请求比所有其他用的请求都更快的到达了服务器，这个时候如果库存足够，就会出现redis预减多次，而只能下单成功一次（前提是：这个用户的多个请求比网站的其他用户的请求都更快的到达服务器，这在网络环境不可知的情况下，基本不可能）

（2）   还有就是在生成订单的过程中发生了不可预料的异常，也会导致redis扣减成功，而db扣减失败（如果是DB出现了异常，可能所有的订单都无法生成，但是只要存在redis预减，活动就可以正常结束）

因此，在初始化的时候，redis中的数量可以多于db的库存数量。

出现这种情况的后果是什么？

（1）   对用户而言，秒杀不中是正常现象，秒杀中才是意外，单个用户能否秒杀中本来就是小概率事件，出现这种情况对用户而言是没有任何影响的。

（2）   对商户而言，本来就是为了做活动拉流量拉人气的，卖不完还可以省一部分费用，但是活动还是正常参与了，也是没有任何影响

（3）   对网站而言，网站最重要的是用户体验，只要网站不崩，用户不骂娘，对网站也没有任何影响。

所以，卖不完是完全允许的，但是卖超是绝对不允许的！卖超的这部分钱商家是不会出的，需要网站自己来出。

## 7.  为什么Redis中的数量会减成负数？

假如redis中的数量是1，这个时候同时过来100个请求，大家一起去执行decr,数量就会减成-99，这是正常的。

## 8.  为什么要单独维护一个秒杀结束的标志？

（1）   前面也提过，所有的秒杀相关的接口都要加上活动是否结束的标志，如果结束就直接返回了，包括轮询的接口，防止一直轮询没法结束。

（2）   管理后台也可以手动的更改这个标志，防止出现活动开始以后就没法结束这种意外的发生。

## 9.  如果用户秒杀成成功了，但是没有付款怎么办？

一般网站都会有下单30分钟不支付订单自动取消这样的操作，此时就需要把库存再加回去，因此又叫回仓。

可以在创建订单以后，把订单写入到延迟队列里面（RabbitMQ、RocketMQ都支持），如果在有效期之内用户做了付款，则从队列删除，否则等延迟队列数据出队的时候，再去查询数据库订单的状态，如果是未支付则需要回仓。回仓无非就是重置redis和mysql的数据，包括一些秒杀结束的状态等等。

## 10.  为什么要做隐藏秒杀接口地址？

（1）   html是可以被右键->查看源代码，如果秒杀地址写死在源文件中，是很容易就被恶意用户拿到的，就可以被机器人利用来刷接口。

（2）   通过一个接口来返回秒杀地址的好处是，可以在活动临近开始的时候，服务端可以把地址换掉，这样就算恶意用户提前拿到了地址，但是拿到的也是一个不可用的地址。

（3）   服务端可以通过管理后台来随时修改接口的地址。

## 11. 项目可改进的地方

- 对于数据的动静分离没有做的很彻底，只是用到了浏览器缓存，没有使用CDN等技术

- 没有设置降级的方案

  降级是从系统功能优先级的角度考虑如何应对系统故障。

  服务降级指的是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。

- 限流做的不够完善，目前只对用户对于某个商品的访问做了限流，没有对整体的流量做限流，比如不法分子有非常多的账号，同时对一个商品发起请求可能造成我们的服务不可用。

- 没有考虑redis穿透的情况处理方案

- 在这个项目中是对库存和静态数据进行了预热，但是实际中有可能某个商品可能一时间快速爆火，如果没有对这些是商品数据进行预热可能会使服务宕掉，需要快速发现热点数据的发现与隔离，比如某明星粉丝约定某一时刻购买某粉丝代言的产品，虽然该商品没有参加秒杀活动，但那一时刻也胜似秒杀

- 对于部署还没有进行实际的操练和学习，可以使用Ngnix做负载均衡

## 12.**分布式Session是怎么实现的**

- 用户登录后生成随机字符串，并向cookie中写入此字符串。
- 在Redis中记录此字符串和用户信息的映射
- 当用户再次访问网页时，取出cookie中对应字段值，根据此字段值访问Redis得到用户相关信息

## 13. 如何解决超卖?

超卖问题主要依靠MySQL中排它锁实现的
在减库存时设置sql语句where中stock>0

##14. 如何解决重复下单？

执行减库存下订单逻辑前，判断是否在订单表中含有用户秒杀此商品的记录
利用唯一索引，在订单表中创建user_id和good_id组成的唯一索引，这样在重复插入数据的时候会插入失败，之前的减库存操作在事务中也会回滚。

## 15. 如何防刷？

对一个商品秒杀时Redis会记录一个用户对一个商品的秒杀按钮的点击次数，如果用户对按钮点击次数超过5次直接返回多次请求提示
但是并没有对所有流量进行限流（具体见项目的不足第二条）
##16. 消息队列的作用？

削峰，减少同一时刻并发量
入队后直接返回用户排队中消息，提高用户体验
##17. 压测？

JMeter压测
10个线程一秒5000并发量，未优化前1300QPS，优化后2100QPS

## 18. 如果项目中的redis服务挂掉，如何减轻数据库的压力？高可用

- 设置本地缓存

- 设置限流降级功能

  **限流是从用户访问压力的角度来考虑如何应对系统故障。**

  限流为了对服务端的接口接受请求的频率进行限制，防止服务挂掉。比如某一接口的请求限制为 100 个每秒, 对超过限制的请求放弃处理或者放到队列中等待处理。限流可以有效应对突发请求过多。

  **降级是从系统功能优先级的角度考虑如何应对系统故障。**

  服务降级指的是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。

- 集群

  相同的服务部署多份，避免单点故障。

- 做好参数校验

## 19. 假如减了库存但用户没有支付，怎么将库存还原继续进行抢购？

- 订单超时未支付则删除订单，增加库存数量，恢复Redis缓存和本地缓存的数量
- 但是对于秒杀项目之所以采用下订单减库存而不是付款减库存，不就是因为秒杀商品秒到就是赚到大概率不会不付款嘛。另外即使不付款，那就不会发货，只会少卖不会超卖对于商户也不会有什么损失吧。

## 20. 项目难点及问题解决？

- 数据一致性：防止超卖和重复下单

- 如何应对高并发：消息队列，读写分离，分库分表，负载均衡

  **消息队列**

  消息队列在分布式系统中主要是为了解耦和削峰。

  **读写分离&分库分表**
  读写分离主要是为了将数据库的读和写操作分不到不同的数据库节点上。主服务器负责写，从服务器负责读。另外，一主一从或者一主多从都可以。

  读写分离可以大幅提高读性能，小幅提高写的性能。因此，读写分离更适合单机并发读请求比较多的场景。

  分库分表是为了解决由于库、表数据量过大，而导致数据库性能持续下降的问题。

  常见的分库分表工具有：sharding-jdbc（当当）、TSharding（蘑菇街）、MyCAT（基于 Cobar）、Cobar（阿里巴巴）...。 推荐使用 sharding-jdbc。 因为，sharding-jdbc 是一款轻量级 Java 框架，以 jar 包形式提供服务，不要我们做额外的运维工作，并且兼容性也很好。

  **负载均衡**
  负载均衡系统通常用于将任务比如用户请求处理分配到多个服务器处理以提高网站、应用或者数据库的性能和可靠性。

  常见的负载均衡系统包括 3 种：

  DNS 负载均衡 ：一般用来实现地理级别的均衡。
  硬件负载均衡 ： 通过单独的硬件设备比如 F5 来实现负载均衡功能（硬件的价格一般很贵）。
  软件负载均衡 ：通过负载均衡软件比如 Nginx 来实现负载均衡功能。

- 如何保持高可用：限流、降级、熔断、排队、集群、超时和重试机制

  **限流**
  限流是从用户访问压力的角度来考虑如何应对系统故障。

  限流为了对服务端的接口接受请求的频率进行限制，防止服务挂掉。比如某一接口的请求限制为 100 个每秒, 对超过限制的请求放弃处理或者放到队列中等待处理。限流可以有效应对突发请求过多。

  **降级**
  降级是从系统功能优先级的角度考虑如何应对系统故障。

  服务降级指的是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。

  **熔断**
  熔断和降级是两个比较容易混淆的概念，两者的含义并不相同。

  降级的目的在于应对系统自身的故障，而熔断的目的在于应对当前系统依赖的外部系统或者第三方系统的故障。

  **排队**
  另类的一种限流，类比于现实世界的排队。玩过英雄联盟的小伙伴应该有体会，每次一有活动，就要经历一波排队才能进入游戏。

  **集群**
  相同的服务部署多份，避免单点故障。

- 接口防刷

